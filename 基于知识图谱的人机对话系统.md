refer:<br>[基于知识图谱的人机对话系统方法与实践 - 2018AI 科技大本营在线公开课](https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/83247433)<br>[知性会话：基于知识图谱的人机对话系统方法与实践 - 2017中国大数据技术大会（BDTC）](https://doc.huodongjia.com/detail-6467.html)
[pdf](百度网盘-AI科技大本营知识图谱公开课（云知声）.pdf)


#### 交互形式和应用场景

+ 交互形式

1. 闲聊。典型代表是小冰，它包括问候和寒暄，其特点是没有明确目的，而且不一定回答用户的问题。聊天在现有的人机对话系统中主要是起到情感陪伴的作用。

2. 问答。它要对用户的问答给出精准的答案。这些问题可以是事实性的问题，如“姚明有多高”,也可能是其他定义类，描述类或者比较类的问题。问答系统可以根据问答的数据来源分为基于常见问题-答案列表的FAQ问答，基于问答社区数据的CQA问答，基于知识库的KBQA问答。

3. 任务式对话。它是一个目的性很强的对话，目标是收集信息，以完成某个填表单式的任务，最常见的像订外卖、订酒店、订机票，这种方式通过对话来做。

   另一种形式是操控，只是解析出它的语义，来供第三方执行，最典型的操控是打开空调、打开台灯，或者播放某一首歌。

4. 主动对话。让机器主动发起话题，不同的是，前面的交互都是让人来主动发起这个交互。

+ 应用场景

  目前人机对话系统的应用场景有很多，像音箱、电视、空调等等，其显著特点是它不是人可以直接触摸到的，可以将语音交互看成遥控器的一种替代品，有遥控器的地方就可以用语音来交互。

  在**车载**方面，因为在开车时，你的眼睛和手脚都被占用着，所以这时通过语音来接听电话、导航甚至收发微信，是非常方便的，也比较安全。车载是刚需场景，所以目前出货量最多是在这块。像我们是从 2014 年开始做车载语音交互方案，到现在有 1500 多万的出货量。

  **儿童教育机器人**，右下角这些各种形状的儿童机器人，实际上可以看成儿童版的音箱，它的内容是面向儿童的，但是交互形式也是人机对话的方式。



#### 技术架构

1、语音识别：主要解决复杂真实场景噪声、用户口音多样的情况下，把人说的话转成文字，即做到“听得清”。

近讲 - 口音问题 （Siri - 一般建议离麦克风的距离是30cm左右）

远讲 - 噪音混响问题、语音唤醒（Amazon Echo - 一般离麦克风 3 米甚至 5 米这么远。）

2、语义理解：主要是把用户说的话转成机器能理解执行的指令或查询，即做到“听得懂”。

3、对话管理：维护对话状态和目标，决定系统应该怎么说、怎么问下一句话，也就是生成一个应答的意图。

4、自然语言生成：就是根据系统应答的意图，用自然语言把这个应答意图表达出来。

5、语音合成： 用机器合成的语音把这句话播报出来。

这样形成一个完整人机对话的闭环。

#### 语境

人和设备对话的时候有哪些语境呢？ 

1、物理语境。也就是你说话当时现场的信息，包括（1）时间、地点、场所，这个场所是指在车里或在家里等等。（2）天气。（3）情绪和情感。（4）设备上面显示的内容。（5）设备能感知到的信息，比如我们和空调对话，空调能够感知到室内外的温度、湿度。这个语境的生命周期是**请求级**的。

2、言语语境。（1）上下文，设备上和设备上面反馈的信息也是一种上下文。（2）主题及焦点。（3）设备反馈。这个生命周期可以看成是**会话级**的。

3、知识语境。包括：（1）人类的常识和领域知识。举个简单的例子，以前我们一句话叫「中国乒乓球队谁也赢不了」，还有「中国足球队也是谁也赢不了」，这两句话看起来字面是一样的，但人能够理解这两句话的差别，因为我们有常识是：中国足球队很弱，中国乒乓球队很强。所以知识对这句话的理解至关重要。（2）用户画像，包括用户的一些基本信息，用户的性别、年龄、文化水平、爱好等等。（3）Agent 画像，就是这个机器人定义的信息，像小冰把它的 Agent 画像定义为一个 18 岁的邻家小妹。（4）设备信息库，如果把音箱作为中控的话，中控连接的设备信息、设备状态等都是语境。如果在家里对中控说「我回家了」这句话到底是什么含义？中控可能会根据你的设备状态、根据当前的环境情况，给你决定是开灯还是关灯，是给你开窗户还是拉窗帘等等。这个生命周期可以看成是**长期**的。

#### 知识图谱

以知识图谱为中心，通过实体发现与链接技术把各种各样可以用来作为对话的数据源融合在一起，实现跨领域、跨交互形式的多轮对话。

示例：

![知识图谱](https://github.com/bifeng/dialogue-system/raw/master/image/knowledge_graph_based_human_machine_interaction.png)

这个例子的话，它涉及很多跟音乐相关的知识，还包括一些歌星的人物相关的知识。交互形式有聊天、问答、操控、主动对话，是通过知识把它们关联在一起，你会感觉整个对话是个很流畅的对话。

主要特点：

**一是跨领域**，跨交互形式共享上下文，你可以看它的聊天和问答可以衔接在以前；**二是它体现了领域专家的机器人定位**，它对这些领域的知识非常了解，可以在聊天或者问答中体现出它掌握的领域知识。它有这方面的知识后，也可以主动发起一些对话。

##### 核心技术

- 离线处理，首先要有知识图谱，所以有一个知识图谱构建的问题。另外，我们要把各种跟对话相关的数据通过实体发现与链接技术跟知识图谱关联起来。
- 在线处理。基于知识做话语理解，怎么在聊天里把知识融合进去，还有基于知识图谱的问答，基于知识图谱的主动对话等。

##### 构建方法

![知识图谱构建方法](https://github.com/bifeng/dialogue-system/raw/master/image/domain_knowledge_graph_construct_method.png)

第一步是做模式设计，我们要定义有哪些类或概念、哪些属性或关系。

第二步确定我们的知识从哪来，所谓的数据来源，这里可以通过对一些结构化的数据、非结构化的数据做转换、对非结构化的数据，即文本，从里面去信息抽取。

第三步，知识图谱里最重要的是词汇的挖掘，各种同义词、缩略词、短语等等。

第四步，有词汇不够，我们要把同义词聚集为一个概念，也就是所谓的实体发现，包括实体实现、实体归类、实体链接等等。

第五步，除了实体之外，知识图谱里还有边，也就是关系，我们要做关系的抽取。

第六步，因为我们的知识图谱可能来源于不同的数据源，所以我们要做知识的融合，主要是实体对齐、属性融合、值的规范化。

最后，对知识图谱的质量做检查控制，包括知识的补全，有错的话要纠错，还有知识更新，最后形成一个领域的知识图谱。

##### 敏捷构建

![敏捷构建](https://github.com/bifeng/dialogue-system/raw/master/image/smart_construct.png)

现在做应用很多情况都是做敏捷开发，也就是说可能半个月或者一个月就会发一次版本，这时候我们知识图谱也要跟着应用快速迭代，这时候是需要对知识图谱敏捷构建的过程。这里强调我们要对知识图谱做自动化的测试，测试完之后要判断它是否能够发版，发版之后要继续分析它目前的问题。可以把知识图谱看成一个软件，它是不是有哪些 bug 或者需要哪些新功能，根据这些制定下一个版本的发版计划。核心想法就是把知识图谱也看成是一个软件，也要有版本管理，也要有敏捷的开发。

paper: 肖仰华：领域知识图谱落地实践中的问题与对策，2018

##### 评估方法

![知识图谱评估方法](https://github.com/bifeng/dialogue-system/raw/master/image/knowledge_graph_evaluation_method.png)

评估的方法基本可以分为四大类别：最重要的类别是第二类基于应用，把知识图谱在应用里看效果怎样，通过应用效果来间接评估知识本体。我们不要先找几十个人花一两年建知识图谱然后再去找应用，而是知识图谱必须是应用驱动的，根据应用效果来评价知识图谱，这是推荐的一个方法。

还有基于黄金标准评估，也就是说如果我们有些好的知识图谱，或者我们可以建一个小的知识图谱，根据这个标准知识图谱去评估我们建的知识图谱的情况。我们可以看看计算概念和关系的覆盖率，即有多少出现在标准知识图谱中的概念和关系被包含了，这可以评价我们的建的知识图谱是否完整。

另外，简单的评估方式基于指标。可以定一些统计指标，比如这个知识图谱里有多少概念、多少关系、关系属性，然后我们还可以对它进行抽查，看它的准确率、一致性等指标。

paper: 袁凯琦, 邓扬, 陈道源, 张冰, 雷凯, 沈颖. 医学知识图谱构建技术与研究进展. 2018, 35(7)

##### 实体发现与链接

主要解决两个问题，一个是我们同一个意义可能有表达不同的形式，像「科比」、「黑曼巴」、「科神」很多是指的科比这个人。还有一个是自然语言或者字符串本身有歧义性，就像「苹果」可能是指苹果电脑、苹果手机，也可能是一个水果。

解决方法：所以它的做法是分两步，实体发现和实体链接，实体发现是发现文本中的 mention，就是字符串，像「这个苹果很贵」的「苹果」是 mention。实体链接是把这个 Mention 和知识图谱里的实体关联起来，知识图谱里的实体关于「苹果」可能有多个实体，有苹果公司，还有苹果这个品牌，还可能是苹果手机、苹果电脑，还有水果叫苹果等等，这里的「苹果」到底指哪个呢？可能要靠上下文的判断。

示例：

我们在对话这块的数据来源有几个：一个是聊天库，像「你喜欢歌手谢霆锋吗」「喜欢，他很酷。」，还有 FAQ 库，我们可能从百度知道或者很多地方可以找到社区问答的数据，就像这里说「谁能说说李健的音乐风格？」「李健的风格，有民谣的简洁，但比民谣华丽得多。」

 我们也会从网上找到很多文档，包括百科的文档或者网页性的文档，我们对这些文档、聊天库、FAQ 库、文档库，我们都要去做实体链接，把这里面出现的歌手和我们知识图谱的歌手关联起来。

解决步骤：

第一步预处理，首先建立一个 mention 到 entity（实体）的关系，这也是目前这个算法的局限性，我们事先要知道一个 mention 可能对应到哪些实体。然后抽取实体相关特征： 

一是实体的先验概率。就像苹果可能是水果的先验概率为 40%，是苹果手机的先验概率为 60%，如果我们说葡萄呢？可能葡萄是水果的先验概率有 90%，10% 是其他东西。二是实体上下文的词分布，我们看这些实体周边到底是什么词，或者它篇章的主题词，就像苹果手机出现在文章里都是科技类的主题词。三是实体之间的语义关联度，因为知识图谱是一个图的结构，所以每个实体环绕它周边都有些其他的实体，这些实体都是相关的特征。

第二步，这时实体链接就变成一个排序问题，找到 mention 之后，我们可以根据前面 mention 关系表找到它的候选实体，现在保持只需要对候选实体排序，返回一个最可能的实体。

第三步，对候选实体进行排序，可以用最基本的方法。这个有两大类：一个是实体本身的信息，还有一个是可以利用实体和实体之间的协同关系做排序。如果是苹果旁边的实体都是偏电脑类的，那这个苹果可能就指苹果电脑。

#### 融合知识的话语理解(spoken language understanding/nlu)

对话系统里最基本的是对用户话语的理解，我们怎么去理解用户说的一句话。

第一步要做实体的发现与链接，像刚才那个例子，「你喜欢谢霆锋吗」，我们要把谢霆锋跟知识图谱的实体关联起来。

第二步做指代发现及消解，比如「你知道他女朋友是谁」，那这个「他」到底是指谁，我们首先要发现他是一个指代词，然后再根据上下文去判断「他」在这个例子里面是谢霆锋这个实体。

另外，我们做语义理解还有一种情况是对候选语义，结合知识做消歧义。比如用户说「周巧文的生日」，因为《生日》是一首歌的名字，周巧文是这个歌的歌手，这时候我们理解它是个音乐，因为本来就在音箱下面，这时我们可以直接播放周巧文的《生日》这首歌。但是如果系统又问一下「刘德华的生日」，这时候虽然我们的命名实体识别很有可能把「生日」也可能打成歌名的标签，刘德华打成歌手的标签，歌手的歌名，很容易以为是播放音乐，但是我们通过知识的验证知道刘德华并没有唱过这首歌，这时候要转成问答，这不是一个操控性的指令。直接返回他的生日，说「刘德华的生日是 1961 年 9 月 27 日」。

这几个例子是我们通过知识帮助去理解用户的指令。

#### 融合知识的聊天

1. 上下文

   seq2seq - 最基本的方法是把上下文的文本跟当前文本的向量合在一起作为 encoder 的输入；另外我们可以把上下文作为向量，在 decoder 阶段输入；或者用主题模型对这个 session 去建模，把这个 session 主题模型也作为 decoder 的输入，这样就可以实现一并上下文的效果。

   paper: 

   A Neural Network Approach to Context-Sensitive Generation of Conversational Responses (2015-06)
   Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models (2015-07)
   Attention with Intention for a Neural Network Conversation Model (2015-10)

2. 一致性

   agent画像，跟我聊天的对象虽然是机器人，但是它有统一的人格，它的性别、年龄、籍贯、爱好应该是一致的，这是目前聊天机器人里面最难的一点。你对机器人问它「多大了？」它可能说「18 岁」，如果你再去问一下「你今年高寿」，它很有可能回答「我今年 88 岁」，或者问你「芳龄几许」，它很有可能回答「小女子今年芳龄二八等等」。

   seq2seq - 把聊天助手的个性信息导入到Decoder的输出过程中，这时候它会优先从身份信息的词向量去生成应答，这样也能达到一定一致性的效果。

   paper: A Persona-Based Neural Conversation Model ACL 2016 [arxiv](https://arxiv.org/abs/1603.06155)

3. 融入百科知识

   做问答的时候，像我们这个例子问「姚明有多高」，我们生成比较自然的问答，说「他是两米二六，他是唯一一个可以从太空看到的人类。」当然，这是开玩笑的。这种聊天就融合了知识，它知道姚明的身高。

   + ...

     构建QA问答对和三元组的对齐语料

     在decode时，用一个逻辑回归控制从语言部分还是知识部分生成next token，产生用自然语言描述的FAQ回复

   + 针对事实型问题，生成自然语言答案
     –识别问句中的实体（默认给定）
     –从知识库中检索相关事实
     –融合问句和相关事实生成自然语言句子形式的答案
   + 生成流利、一致的回复，需要融合如下两类信息
     –实例型知识（与该问题相关的事实）、
     –通用型的“平滑”词（对话模式）

paper:

Neural Generative Question Answering （2016-06）<br>Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence Learning （何世柱 et al. ACL 2017）<br>IJCAI 2018 Distinguished Paper：“Commonsense Knowledge Aware Conversation Generation with Graph Attention”
ACL 2018：“Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems.”

#### 融合知识的问答

知识问答主要有两种方法：一种是基于 Semantic Parsing 的传统方法，它是把一个问题解析成一个形式化的查询语言，再把查询语言知识库里面做查询。这个方法的最大难点是把自然语言的问题转成这样一个形式化的查询语言。同样也有很多方法，最简单的基于规则、基于模板，复杂点的基于翻译模型、基于深度学习模型等。

目前学术界比较多的是基于机器学习的知识库的问答方法，这里面它的基本思想是把问题建模成一个 embedding，然后对知识图谱也做 embedding，变成一个个向量，这个问答就转换成了一个相似度匹配的问题，把知识库里的子图的向量跟问题对应子图进行相似度匹配。

个人观点是现在基于深度学习的知识库问答目前在工业界这块不是很成熟，它的效果不太可控，我们在系统里还是用基于传统的 Semantic Parsing 问答。

paper: 

Losin，《揭开知识库问答KB-QA的面纱》

+ 基于检索-排序方法
  基本步骤
  –Step1：候选生成
  • 利用Entity Linking找到main entity
  • 在KB中main entity周围的entity均是候选
  –Step2：候选排序

  –何世柱，基于深度学习的知识问答与对话

+ 基于记忆网络
  –Large-scale Simple Question Answering with Memory Networks，2015

+ 基于带注意力机制的循环神经网络
  –Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information，2016

  一个上下文引导的注意力神经网络，可将知识图谱中的背景知识嵌入整合到句子表示中
  结合知识型注意力机制模块，对问题和答案中的各个部分进行有效的相互关联

  –CQA：Knowledge-aware Attentive Neural Network for Ranking Question Answer Pairs (SIGIR 2018)

  –CQA：Response Ranking with Deep Matching Networks and External Knowledge in Information-seeking Conversation Systems （SIGIR 2018）

#### 融合知识的主动会话

这个实际上是非常关键的。在我们人机对话系统，特别是在 VUI 交互下， VUI 音箱是没有界面的，这就意味着你无法知道这个音箱到底支持哪些功能。当你面对音箱的时候，你怎么知道它的功能，到底哪些话能说，哪些话不能说，或者它有什么东西？这时候很需要机器人主动的对话，能**引导用户**用它，知道它的功能。

再举个例子，如果一个用户说「来首《传奇》」，机器可以主动问他说「播放以后还想听听李健原唱吗？」其实它的思想很简单，就是根据我们的知识图谱里面，看看相同实体下面有没有其他关系或者属性，或者推荐一个相同关系下面其他的实体。

这里一篇百度的文章思想也是类似的，如果觉得聊天聊不下去了，会先在上下文里去做实体分析和实体链接，找到作为聊天主题的实体之后再根据知识图谱找相关的实体，根据相关的实体产生话题。

paper: StalemateBreaker: A Proactive Content-Introducing Approach to Automatic Human-Computer Conversation



#### QA

Q：我们公司在构建电商的知识图谱，但是电商的数据是每天都会更新的，有什么好的办法对知识图谱进行更新吗？而且基于 neo4j 的图谱如何做知识推理？

A：这是个好问题。我们刚才强调知识图谱要敏捷构建，敏捷构建就意味着你可以频繁的发版本，这时候就有版本合并的问题，其实也是更新的问题。更新这块主要的技术是知识本体的融合或者知识实体的匹配、实体的对齐。如果更新的数据量不是很大的话，我建议的方法是先通过实体对齐的技术，把更新的数据自动添加到知识图谱里去，如果量不大的话还需要做人工的 review，看更新的数据是否 OK。这个我认为也没有什么特别好的办法，因为更新本来就是知识图谱里最难的问题。

neo4j 的图谱如何做知识推理？首先，我个人认为它不太适合存储海量的知识图谱，电商的数量应该很大的，这时候用 neo4j 合适不合适还有待商榷。如何做知识推理？我们一般认为知识图谱最主要的是知识，尽量少去做推理，因为推理是挺难的一个东西，而且也没有特别工业化成熟度很高的工具。第二，如果非要做推理的话，我们一般做线下的推理，就是预先把推理做好，把它能展开的数据全展开，也叫「知识补全」，就像简单的传递性的关系或者预先把它都展开，相当于存储空间换时间，这是一个比较常用的方法。我们现在不太建议线上服务时做实时推理，因为那个性能一般很难达到要求。

Q：本体构建的大致方法能简单介绍一下吗？

A：本体构建的方法从大的面来讲有两种，一种是传统基于专家的方法，就是请一般专家全手工构建，他们对每个词、每个实体、词之间的关系都开会讨论，最后决定应该这样、应该那样，这是专家驱动的方法。但这种方法已经不太可行，而且这种方法也会成为我们做知识图谱的瓶颈，因为我们期望知识图谱是一个敏捷构建的。

 目前大部分是数据驱动的方法，就是我们通过数据挖掘去自动构建知识图谱，适当地基于人工的 review。我倾向于极端的方法，我推荐的方式是知识图谱的构建整个是全自动，但是也需要专家的参与，但是专家参与不是做 review、不是做构建，而是做评测。整个知识图谱的效果根据应用的效果说话，这个应用不能假设整个知识图谱是完全正确的、完整的的。我们可以通过快速迭代，不断的对知识图谱去做更新，然后根据自动化的测试或者根据人工的抽样检查和应用的效果去看知识图谱的质量。只要我们知识图谱的质量能够满足应用的需求就 OK。

Q：实体抽取有一个大致的最佳实践吗？

A：最佳实践是这样的，如果从工业界角度看的话，实体抽取肯定是多个方法的融合，基于词典、基于规则、基于统计学习方法、基于深度学习方法，没有一个方法就能搞定所有的问题。虽然词典挖掘这个东西没有技术含量，但是实践中基于词典的方法是非常有效的方法，特别是在垂直领域里面，像医疗这种领域，当然，在有些领域可能这个方法不靠谱，比如在音乐领域，音乐里面有歌名，任何一个词都可能是歌名。

但基于词典方法还有一个重要考虑，一定要考虑这个词典的这个词有没有歧义，或者一个词的先验概率。比如「我爱你」也是一首歌名，但是它是歌名的概率可能不是特别大，但「忘情水」是歌名的概率就很大，所以词典不是简单的词条列表，而是要带先验概率的信息。

Q：知识图谱还需要语义网的知识吗？构建 OWL 可还需要很强的领域知识？

A：我们刚才说到知识图谱的前身是语义网，所以如果想更加深刻理解知识图谱，还是要了解一下语义网的知识，特别像 RDF OWL 的规范是要了解一下的。

OWL 的这个本体语言还是有点偏复杂，目前基本上不太推荐知识图谱搞得那么复杂，基本对应到 RDF 那种形态就差不多了。我们希望知识图谱可以构建尽量大，但是它从逻辑上来讲尽量简单，不要用 OWL 里面复杂的东西。一点点语义可以走得很远，没必要把模型搞得太复杂，因为把模型搞得太复杂的一个最重要难点是当你把实体放进去时你很难判断这个实体属于哪个概念。

Q：基于知识的方法和统计类的方法需要共融互补，老师有没有典型的合作思路，充分利用基于知识规则方法的稳定可控的同时，又能利用统计从有监督的大数据自动抽取模式？是否可以讲讲两者一起 NLP 的经验？

A：现在人工智能主要是三大学派——知识图谱派、统计学习派、深度学习派，从工业界角度来看，在解决具体问题时各有所长，所以需要把这三者融合在一起，真实的线上系统不会只有一个方法。所以知识方法是一个很重要的方法，而且它跟深度学习是有比较好的互补性，特别是可以提供深度学习方法里面没有的可解释性这一块。

最简单的融合方法就是做模型Ensemble，把几个分类器组装在一起，这个可以看周志华老师那本「西瓜书」，因为周老师做模型的 Ensemble是最拿手的。

此外，把知识或规则都可以作为特征，从这个角度融合在一起。另外，深度学习里的解码器也可以把知识融合进来，所以这块的方法是很多的。
